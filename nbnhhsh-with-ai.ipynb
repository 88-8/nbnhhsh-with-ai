{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> åˆæ­¥æ„æƒ³ï¼Œæœ‰å¾…å®Œå–„â€¦â€¦","metadata":{}},{"cell_type":"markdown","source":"# Description\nğŸ¤–ã€Œèƒ½ä¸èƒ½å¥½å¥½è¯´è¯ï¼Ÿã€æ‹¼éŸ³é¦–å­—æ¯ç¼©å†™~~æŸ¥è¯~~ç¿»è¯‘å·¥å…·\n\nhttps://github.com/itorr/nbnhhsh","metadata":{}},{"cell_type":"markdown","source":"# Sample\n```json\n[{\n\t'original': 'DLæ˜¯MLçš„ä¸€ä¸ªåˆ†æ”¯ã€‚',\n\t'translation': ['æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ã€‚', 'deadlineæ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ã€‚'],\n\t'dictionary': [{\n\t\t'word': 'dl',\n\t\t'definition': ['å¤§ä½¬', 'æ¯’ç˜¤', 'å†³æ–—é“¾æ¥', 'åˆ€éƒ', 'é‚“ä¼¦', 'æ‡‚äº†', 'ä»£ç»ƒ', 'æ¶ˆé€çš„å…‰èŠ’', 'è¾¾èµ–', 'å¤šç»ƒ', 'dancing line', 'æ¯’é¾™', 'Dua Lipa', 'é¡¶æµ', 'download', 'dlsite', 'å¤§é¾™', 'å¯¹ç«‹', 'è·³èˆçš„çº¿', 'ä»£èŠ(è®ºå›)', 'å¤§æ—', 'ä¸ç£Š', 'deadline', 'æ·±åº¦å­¦ä¹ ', 'ç‹¬ç«‹', 'æœµæ‹‰', 'doctor love ï¼ˆæ˜æ—¥æ–¹èˆŸï¼‰', 'åœ°ç†', 'æ±ªä¸œåŸxç‚äºšçº¶', 'å‘†é©´', 'ä¸‹è½½']\n\t}, {\n\t\t'word': 'ml',\n\t\t'definition': ['Make Love', 'é©¬é¹¿', 'æ‘¸äº†', 'æ¢…æ—å›ºä»¶', 'å¶åƒå¤§å¸ˆç™¾ä¸‡ç°åœº', 'M League', 'ç äº†', 'é©¬é¾™', 'æœºå™¨å­¦ä¹ ', 'Machine Learning', 'master love', 'æ¢…è‰ï¼ˆä¸œæ–¹Projectäººç‰©ï¼‰', 'é©¬åˆ—ï¼ˆé©¬å…‹æ€åˆ—å®ï¼‰', \"Mao's legacyï¼ˆæ¸¸æˆåç§°ï¼‰\", 'æ¢…æ—ä¼ å¥‡', 'Making Lovers(æ¸¸æˆåç§°)', 'æ¯«å‡ï¼ˆå•ä½ï¼‰', 'ç±³å…°', 'å…æµ', 'éº»äº†', 'é©¬ä¸½(æ¼”å‘˜)', 'é©¬ç³', 'ç±³æ´›ï¼ˆupä¸»ï¼‰', 'å†¥é¾™ï¼ˆå…‰é‡ï¼‰', 'Margin Left(HTML)']\n\t}]\n}]\n```","metadata":{}},{"cell_type":"markdown","source":"# Demo","metadata":{}},{"cell_type":"code","source":"# åŠ è½½è¯­è¨€æ¨¡å‹\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef load_model(path):\n    tokenizer = AutoTokenizer.from_pretrained(path)\n    model = AutoModelForCausalLM.from_pretrained(path).to(device)\n    model.eval()\n    return tokenizer, model\n\ntokenizer, model = load_model(\"uer/gpt2-chinese-cluecorpussmall\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-14T11:43:19.195469Z","iopub.execute_input":"2022-11-14T11:43:19.196621Z","iopub.status.idle":"2022-11-14T11:43:49.950690Z","shell.execute_reply.started":"2022-11-14T11:43:19.196521Z","shell.execute_reply":"2022-11-14T11:43:49.949668Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/217 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd8346864f24a9e83a10f53cafdafd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/577 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"129ec382a7bb4b88ac7fdeca7dffd8e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/107k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc7f3b0321848689303d577038083c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"331ddccefc3a4c3db96f6d3ecdafce40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/401M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39d1631405124fb5b93ea5a42ac803d0"}},"metadata":{}}]},{"cell_type":"code","source":"# åŠ è½½å·¥å…·å‡½æ•°\n\nimport math, requests, json, re, itertools, time\n\ndef query(text): # ä¸Šä¼ åˆ°ã€Œèƒ½ä¸èƒ½å¥½å¥½è¯´è¯ï¼Ÿã€é¡¹ç›®æŸ¥è¯¢\n    query = \",\".join(list(set(re.findall(\"[A-Za-z0-9]{2,10}\", text)))).lower() # æå–å­—æ¯ã€æ•°å­—åºåˆ—ï¼Œå‰”é™¤é¡ºåºã€å¤§å°å†™ä¿¡æ¯\n    if not query: return {}\n    response = requests.post(\"https://lab.magiconch.com/api/nbnhhsh/guess\", headers={\"Content-Type\":\"application/json\"}, data=json.dumps({\"text\":query}))\n    results = json.loads(response.text)\n    dictionary = {}\n    for data in results:\n        if \"trans\" in data: # é‡Šä¹‰ï¼ˆç”¨æˆ·æäº¤ï¼‰\n            dictionary[data[\"name\"]] = data[\"trans\"]\n        elif \"inputting\" in data: # çŒœæµ‹ï¼ˆç¨‹åºæ¨æµ‹ï¼‰ï¼ˆæ— ç”¨æˆ·æäº¤æ•°æ®æ—¶ï¼Œä¼šä½œä¸ºæ‹¼éŸ³é¦–å­—æ¯ã€è¯ç»„é¦–å­—æ¯æŸ¥è¯¢ï¼‰\n            dictionary[data[\"name\"]] = data[\"inputting\"]\n    return dictionary\n\ndef get_perplexity_score(sentence):\n    tokenize_input = tokenizer.tokenize(sentence)\n    tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)]).to(device)\n    if tensor_input.size()[1] <= 0: return None\n    predictions = model(tensor_input, labels=tensor_input)\n    loss = predictions[0]\n    return math.exp(loss)\n\ndef get_perplexity_ranking(sentences):\n    result = [[sentence, get_perplexity_score(sentence)] for sentence in sentences]\n    result.sort(key=lambda data: data[1])\n    return result\n\ndef get_translation_data(text, dictionary): # ç¿»è¯‘æ ‡è®°æ•°æ®ï¼Œä¾‹ï¼š[[DL,æ·±åº¦å­¦ä¹ ,ä¸‹è½½,åœ°ç†],æ˜¯,[ML,æœºå™¨å­¦ä¹ ,æ¯«å‡],çš„ä¸€ä¸ªåˆ†æ”¯]\n    data = [str(text)]\n    for key in reversed(sorted(dictionary.keys(), key=len)):\n        if len(dictionary[key]) < 1: continue\n        definition = dictionary[key]\n        definition = [re.sub(\"[\\(ï¼ˆ].*?[\\)ï¼‰]\", \"\", _) for _ in definition] # æ¸…æ´—è¯å…¸é‡Šä¹‰\n        definition = [key] + definition\n        index = 0\n        while index < len(data):\n            if not isinstance(data[index], str): continue # å¿½ç•¥å·²æ ‡è®°æ¡ç›®\n            text = data.pop(index)\n            texts = text.lower().split(key.lower()) # å¿½ç•¥å¤§å°å†™\n            dat = list(itertools.chain.from_iterable([_, definition] for _ in texts))[0:-1]\n            for i in range(len(dat)): data.insert(index + i, dat[i])\n            index += len(dat)\n            index += 1\n    return data\n\ndef get_translation_sentences(data): # æ ¹æ®ç¿»è¯‘æ ‡è®°æ•°æ®ç”Ÿæˆæ‰€æœ‰ç»„åˆ\n    data = [([_] if isinstance(_, str) else _[1:]) for _ in data]\n    sentences = [\"\".join(_) for _ in itertools.product(*data)]\n    return sentences\n\ndef get_estimated_time(sentences): # æ¨ç†ä¸€æ¬¡ä»¥ä¿å®ˆä¼°è®¡æ•´ä½“è€—æ—¶\n    test = list(sorted(sentences, key=len))[-1]\n    start = time.perf_counter()\n    get_perplexity_ranking([test])\n    return (time.perf_counter() - start) * len(sentences)\n\ndef translate(text): # ç¿»è¯‘æ¥å£å‡½æ•°ï¼Œè¿”å›æ ¼å¼åŒ–ç»“æœ\n    if text == \"\" or not isinstance(text, str): return []\n    dictionary = query(text)\n    regex = re.compile(\"[\\nã€‚ï¼ï¼Ÿï¼›]+\")\n    sents = regex.split(text)\n    puncs = regex.findall(text)\n    puncs.append(\"\")\n    texts = list(map(lambda sent, punc: sent + punc, sents, puncs))\n    texts = [text for text in texts if text]\n    # é¢„ä¼°è€—æ—¶å¹¶ä½œé™åˆ¶\n    sents = [get_translation_sentences(get_translation_data(texts[index], dictionary)) for index in range(len(texts))]\n    etime = get_estimated_time(sum(sents, []))\n    if etime > 60: return [[{ \"original\": text, \"translation\": f\"éš¾ä»¥è®¡ç®—ï¼Œè¯·ç¼©çŸ­è¾“å…¥æˆ–å‡çº§æœºå™¨ã€‚ï¼ˆå½“å‰è®¾å¤‡ï¼š{str(device)}ï¼Œé¢„è®¡è€—æ—¶ï¼š{str(round(etime))}sï¼‰\", \"dictionary\": dictionary }]]\n    # ---------------\n    results = []\n    for index in range(len(texts)):\n        text = texts[index]\n        data = get_translation_data(text, dictionary)\n        sentences = get_translation_sentences(data)\n        translation = []\n        ranking = get_perplexity_ranking(sentences)\n        maximum = 3 # æœ€å¤§è¾“å‡ºæ•°é‡\n        score = min(ranking[0][1] + 50, ranking[0][1] * 2) # å›°æƒ‘åº¦é˜ˆå€¼ï¼Œä»¥æœ€ä¼˜é€‰ä¸ºåŸºå‡†è®¡ç®—å¾—å‡º\n        for i in range(len(ranking)):\n            if i >= maximum or ranking[i][1] > score: break\n            translation.append(ranking[i][0])\n        dic = []\n        for item in data:\n            if isinstance(item, str): continue\n            word = item[0]\n            entry = { \"word\": word, \"definition\": dictionary[word] }\n            if entry in dic: continue\n            dic.append(entry)\n        results.append({ \"original\": text, \"translation\": translation, \"dictionary\": dic })\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-11-14T11:45:26.026842Z","iopub.execute_input":"2022-11-14T11:45:26.028917Z","iopub.status.idle":"2022-11-14T11:45:26.084358Z","shell.execute_reply.started":"2022-11-14T11:45:26.028854Z","shell.execute_reply":"2022-11-14T11:45:26.083367Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# è¿è¡Œæµ‹è¯•æ•ˆæœ\n\nprint(translate('ä½ è¦åŒæˆ‘åšAIå—ï¼ŸNLPè¿˜æ˜¯CVï¼Ÿ'))\nprint(translate('jmmå†²å•Šè¿™ä¸ªncçœŸçš„æ— æ•Œå¥½å–åˆ°ç¿˜jiojioï¼ï¼ï¼'))","metadata":{"execution":{"iopub.status.busy":"2022-11-14T11:49:04.210576Z","iopub.execute_input":"2022-11-14T11:49:04.210967Z","iopub.status.idle":"2022-11-14T11:49:17.588814Z","shell.execute_reply.started":"2022-11-14T11:49:04.210936Z","shell.execute_reply":"2022-11-14T11:49:17.587760Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[{'original': 'ä½ è¦åŒæˆ‘åšAIå—ï¼Ÿ', 'translation': ['ä½ è¦åŒæˆ‘åšäººå·¥æ™ºèƒ½å—ï¼Ÿ', 'ä½ è¦åŒæˆ‘åšçˆ±å—ï¼Ÿ'], 'dictionary': [{'word': 'ai', 'definition': ['illustrator', 'è‰¾ä¼¦è‰¾å¼—æ£®', 'ç¾å›½å¶åƒ', 'äººå·¥æ™ºèƒ½', 'å†³å®šç”Ÿç‰©å¦‚ä½•è¡ŒåŠ¨(Minecraft)', 'çˆ±']}]}, {'original': 'NLPè¿˜æ˜¯CVï¼Ÿ', 'translation': ['è‡ªç„¶è¯­è¨€å¤„ç†è¿˜æ˜¯è®¡ç®—æœºè§†è§‰ï¼Ÿ', 'è‡ªç„¶è¯­è¨€å¤„ç†è¿˜æ˜¯å¤åˆ¶ç²˜è´´ï¼Ÿ'], 'dictionary': [{'word': 'nlp', 'definition': ['ä½ è€å©†', 'è‡ªç„¶è¯­è¨€å¤„ç†']}, {'word': 'cv', 'definition': ['é…éŸ³æ¼”å‘˜', 'èˆªç©ºæ¯èˆ°', 'å£°ä¼˜', 'å¤åˆ¶ç²˜è´´', 'è®¡ç®—æœºè§†è§‰', 'ç®€å†']}]}]\n[{'original': 'jmmå†²å•Šè¿™ä¸ªncçœŸçš„æ— æ•Œå¥½å–åˆ°ç¿˜jiojioï¼ï¼ï¼', 'translation': ['å§å¦¹ä»¬å†²å•Šè¿™ä¸ªå¥¶èŒ¶çœŸçš„æ— æ•Œå¥½å–åˆ°ç¿˜è„šè„šï¼ï¼ï¼', 'å§å¦¹ä»¬å†²å•Šè¿™ä¸ªNormal ClearçœŸçš„æ— æ•Œå¥½å–åˆ°ç¿˜è„šè„šï¼ï¼ï¼', 'å§å¦¹ä»¬å†²å•Šè¿™ä¸ªNuclear ChemistryçœŸçš„æ— æ•Œå¥½å–åˆ°ç¿˜è„šè„šï¼ï¼ï¼'], 'dictionary': [{'word': 'jmm', 'definition': ['é‡‘è‹—è‹—', 'åæ™¨å®‡', 'å§å¦¹ä»¬', 'é›†ç¾ä»¬', 'å·æ¯›çŒ«']}, {'word': 'nc', 'definition': ['è„‘æ®‹', 'ä½ çŒœ', 'Nice', 'é™ˆå·', 'å¥¶èŒ¶', 'nightcore', 'çº³ç²¹', 'ç‰›ç¿', 'Nathan Chené™ˆå·', 'no chance', 'èƒ½carry?', 'Normal Clear', 'å†œæ‘', 'å†…å­˜', 'æ˜µç§°', 'å—æ˜Œ', 'no children', 'å“ªåƒ', 'ç¦æ­¢å•†ä¸šä½¿ç”¨ï¼ˆNoncommercialï¼‰', 'Nuclear Chemistry']}, {'word': 'jiojio', 'definition': ['è„šè„š']}]}]\n","output_type":"stream"}]}]}